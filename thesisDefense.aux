\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{abbreviations}{glg-abr}{gls-abr}{glo-abr}
\providecommand\@glsxtr@savepreloctag[2]{}
\@newglossary{symbols}{symbols-glg}{symbols-gls}{symbols-glo}
\providecommand\@glsorder[1]{}
\providecommand\@istfilename[1]{}
\@istfilename{thesisDefense.ist}
\@glsorder{word}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{ix}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Figures}{x}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{gordy2010nested}
\citation{gordy2010nested}
\citation{broadie2015risk}
\citation{broadie2015risk}
\citation{hong2017kernel}
\citation{feng2020optimal}
\citation{zhang2022sample}
\citation{barton1998simulation}
\citation{giles2019multilevel}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Nested Simulation Procedures in Financial Engineering: A Selected Review}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{3}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Problem Formulation}{5}{section.2.2}\protected@file@percent }
\newlabel{sec1:problem-formulation}{{2.2}{5}{Problem Formulation}{section.2.2}{}}
\newlabel{def1:smooth}{{1}{5}{Problem Formulation}{definition.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Smoothness assumption of $h$ for different nested simulation procedures}}{6}{table.caption.8}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab1:smoothness}{{2.1}{6}{Smoothness assumption of $h$ for different nested simulation procedures}{table.caption.8}{}}
\newlabel{def1:lipschitz}{{2}{6}{Problem Formulation}{definition.2}{}}
\newlabel{def1:indicator}{{3}{6}{Problem Formulation}{definition.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}The Standard Nested Simulation Procedure}{6}{subsection.2.2.1}\protected@file@percent }
\citation{gordy2010nested}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Multi-level Monte Carlo}{7}{subsection.2.2.2}\protected@file@percent }
\citation{giles2015multilevel}
\citation{giles2019multilevel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Supervised Learning Models}{8}{subsection.2.2.3}\protected@file@percent }
\citation{broadie2015risk}
\citation{hong2017kernel}
\citation{wang2022smooth}
\citation{hong2017kernel}
\citation{mack1981local}
\citation{zhang2022sample}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Likelihood Ratio Method}{11}{subsection.2.2.4}\protected@file@percent }
\citation{gordy2010nested}
\citation{giles2019multilevel}
\citation{broadie2015risk}
\citation{hong2017kernel}
\citation{zhang2022sample}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Problem Statement}{12}{subsection.2.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Asymptotic Analysis}{12}{section.2.3}\protected@file@percent }
\newlabel{sec1:asymptotic-convergence}{{2.3}{12}{Asymptotic Analysis}{section.2.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Existing asymptotic convergence results of nested simulation procedures for MSE}}{12}{table.caption.9}\protected@file@percent }
\newlabel{tab1:asymConv-mse}{{2.2}{12}{Existing asymptotic convergence results of nested simulation procedures for MSE}{table.caption.9}{}}
\citation{wang2022smooth}
\citation{wang2022smooth}
\citation{gordy2010nested}
\citation{wang2022smooth}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Connections between Convergence in MSE and Absolute Error}{14}{subsection.2.3.1}\protected@file@percent }
\newlabel{sec1:connection-mse-absolute-error}{{2.3.1}{14}{Connections between Convergence in MSE and Absolute Error}{subsection.2.3.1}{}}
\newlabel{thm1:convergence-mse-prob}{{1}{15}{Connections between Convergence in MSE and Absolute Error}{theorem.2.3.1}{}}
\citation{wang2022smooth}
\citation{gordy2010nested}
\citation{gordy2010nested}
\citation{hong2017kernel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Asymptotic Analysis for the Standard Nested Simulation Procedure}{16}{subsection.2.3.2}\protected@file@percent }
\newlabel{as1:sns}{{1}{16}{Asymptotic Analysis for the Standard Nested Simulation Procedure}{assumption.1}{}}
\citation{gordy2010nested}
\newlabel{as1:sns-noise}{{2}{17}{Asymptotic Analysis for the Standard Nested Simulation Procedure}{assumption.2}{}}
\newlabel{eq1:mse-sns}{{2.3}{17}{Asymptotic Analysis for the Standard Nested Simulation Procedure}{equation.2.3.3}{}}
\newlabel{eq1:mse-sns2}{{2.4}{17}{Asymptotic Analysis for the Standard Nested Simulation Procedure}{equation.2.3.4}{}}
\citation{wang2022smooth}
\newlabel{as1:sns-smooth}{{3}{18}{A Smooth Function $h$}{assumption.3}{}}
\newlabel{eq1:taylor-sns}{{2.5}{18}{A Smooth Function $h$}{equation.2.3.5}{}}
\newlabel{eq1:s1-sns}{{2.6}{19}{A Smooth Function $h$}{equation.2.3.6}{}}
\newlabel{as1:sns-noise-var}{{4}{19}{A Smooth Function $h$}{assumption.4}{}}
\citation{gordy2010nested}
\newlabel{eq1:s2-sns}{{2.7}{20}{A Smooth Function $h$}{equation.2.3.7}{}}
\newlabel{eq1:mse-sns-smooth}{{2.8}{20}{A Smooth Function $h$}{equation.2.3.8}{}}
\newlabel{eq1:bias-sns-smooth}{{2.9}{21}{A Smooth Function $h$}{equation.2.3.9}{}}
\newlabel{eq1:bias-sns-smooth-Taylor1}{{2.10}{21}{A Smooth Function $h$}{equation.2.3.10}{}}
\newlabel{eq1:bias-sns-smooth-Taylor2}{{2.11}{21}{A Smooth Function $h$}{equation.2.3.11}{}}
\newlabel{eq1:var-sns-smooth}{{2.12}{21}{A Smooth Function $h$}{equation.2.3.12}{}}
\citation{gordy2010nested}
\citation{gordy2010nested}
\citation{gordy2010nested}
\citation{broadie2015risk}
\newlabel{thm1:sns-smooth}{{2}{22}{A Smooth Function $h$}{theorem.2.3.2}{}}
\newlabel{as1:sns-lip}{{5}{22}{A Lipschitz Continuous Function $h$}{assumption.5}{}}
\citation{gordy2010nested}
\newlabel{eq1:bias-sns-lip}{{2.15}{23}{A Lipschitz Continuous Function $h$}{equation.2.3.15}{}}
\citation{hong2017kernel}
\citation{hong2017kernel}
\citation{hong2017kernel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{24}{subsection.2.3.3}\protected@file@percent }
\citation{mack1981local}
\newlabel{as1:knn}{{6}{25}{Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{assumption.6}{}}
\newlabel{eq1:bias-knn}{{2.17}{26}{Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{equation.2.3.17}{}}
\newlabel{eq1:bias-knn-1}{{2.18}{26}{Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{equation.2.3.18}{}}
\citation{hong2017kernel}
\newlabel{eq1:bias-knn-2}{{2.19}{27}{Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{equation.2.3.19}{}}
\newlabel{def:knn-smooth-bias}{{6}{27}{Asymptotic Analysis of a kNN-based Nested Simulation Procedure for a Smooth Function}{definition.6}{}}
\citation{gordy2010nested}
\citation{broadie2015risk}
\citation{gordy2010nested}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Convergence Orders and Critical Assumptions of Nested Simulation Procedures}{28}{section.2.4}\protected@file@percent }
\newlabel{sec1:convergence-orders}{{2.4}{28}{Convergence Orders and Critical Assumptions of Nested Simulation Procedures}{section.2.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Asymptotic rate of convergence of nested simulation procedures in MSE}}{28}{table.caption.12}\protected@file@percent }
\newlabel{tab1:asymConv-order}{{2.3}{28}{Asymptotic rate of convergence of nested simulation procedures in MSE}{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Standard Assumptions}{28}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Assumptions on Joint Density}{28}{subsection.2.4.2}\protected@file@percent }
\newlabel{as1:sns-joint-density}{{7}{28}{Assumptions on Joint Density}{assumption.7}{}}
\citation{broadie2015risk}
\citation{giles2019multilevel}
\newlabel{as1:sns-joint-density-bound}{{8}{29}{Assumptions on Joint Density}{assumption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Assumptions for the Multi-level Monte Carlo Procedure}{29}{subsection.2.4.3}\protected@file@percent }
\newlabel{as1:mlmc-q}{{9}{29}{Assumptions for the Multi-level Monte Carlo Procedure}{assumption.9}{}}
\citation{hong2017kernel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Assumptions for the Likelihood Ratio-Based Procedure}{30}{subsection.2.4.4}\protected@file@percent }
\newlabel{as1:likelihood-ratio-marginal-density}{{10}{30}{Assumptions for the Likelihood Ratio-Based Procedure}{assumption.10}{}}
\newlabel{as1:likelihood-ratio-independence}{{11}{30}{Assumptions for the Likelihood Ratio-Based Procedure}{assumption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Assumptions for the Kernel-Based Procedure}{30}{subsection.2.4.5}\protected@file@percent }
\citation{zhang2021bootstrap}
\citation{frazier2018bayesian}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Assumptions for the KRR-Based Procedure}{31}{subsection.2.4.6}\protected@file@percent }
\newlabel{as1:krr-domain}{{13}{31}{Assumptions for the KRR-Based Procedure}{assumption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Finite-Sample Experiments}{31}{section.2.5}\protected@file@percent }
\newlabel{sec1:numerical-experiments}{{2.5}{31}{Finite-Sample Experiments}{section.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Empirical convergence of nested simulation procedures for quadratic tracking error on Portfolio 1 with $d=1$}}{33}{figure.caption.13}\protected@file@percent }
\newlabel{fig1:compareAll}{{2.1}{33}{Empirical convergence of nested simulation procedures for quadratic tracking error on Portfolio 1 with $d=1$}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Sensitivity to the Asset Dimension}{34}{subsection.2.5.1}\protected@file@percent }
\newlabel{sec1:sensitivity-dimension}{{2.5.1}{34}{Sensitivity to the Asset Dimension}{subsection.2.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Empirical convergence of nested simulation procedures for quadratic tracking error on Portfolio 1 with different asset dimensions}}{34}{figure.caption.14}\protected@file@percent }
\newlabel{fig1:assetDimension}{{2.2}{34}{Empirical convergence of nested simulation procedures for quadratic tracking error on Portfolio 1 with different asset dimensions}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Empirical Convergence of Parametric Regression Procedures}{35}{subsection.2.5.2}\protected@file@percent }
\newlabel{sec1:regression-convergence}{{2.5.2}{35}{Empirical Convergence of Parametric Regression Procedures}{subsection.2.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Empirical convergence of regression procedure for European call options and $d=20$}}{36}{figure.caption.15}\protected@file@percent }
\newlabel{fig1:reg_lb}{{2.3}{36}{Empirical convergence of regression procedure for European call options and $d=20$}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Empirical Convergence of Kernel Smoothing-Based Procedures}{36}{subsection.2.5.3}\protected@file@percent }
\newlabel{sec1:kernel-smoothing-convergence}{{2.5.3}{36}{Empirical Convergence of Kernel Smoothing-Based Procedures}{subsection.2.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Empirical convergence of kernel smoothing procedure for different values of $d$}}{37}{figure.caption.16}\protected@file@percent }
\newlabel{fig1:kernel_d}{{2.4}{37}{Empirical convergence of kernel smoothing procedure for different values of $d$}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Cross-validation for the kernel smoothing-based procedure with $\Gamma =100,000$}}{38}{figure.caption.17}\protected@file@percent }
\newlabel{fig1:kernel_cv}{{2.5}{38}{Cross-validation for the kernel smoothing-based procedure with $\Gamma =100,000$}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Sensitivity to the Option Types and Risk Measures}{38}{subsection.2.5.4}\protected@file@percent }
\newlabel{sec1:sensitivity-option-type}{{2.5.4}{38}{Sensitivity to the Option Types and Risk Measures}{subsection.2.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Empirical convergence of nested simulation procedures for quadratic tracking error on different portfolios with $d=20$}}{38}{figure.caption.18}\protected@file@percent }
\newlabel{fig1:1x03}{{2.6}{38}{Empirical convergence of nested simulation procedures for quadratic tracking error on different portfolios with $d=20$}{figure.caption.18}{}}
\citation{broadie2015risk}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Empirical convergence of nested simulation procedures for a W-shaped payoff}}{39}{figure.caption.19}\protected@file@percent }
\newlabel{fig1:5503}{{2.7}{39}{Empirical convergence of nested simulation procedures for a W-shaped payoff}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Empirical convergence of nested simulation procedures for different risk measures on Portfolio 1 with $d=20$}}{39}{figure.caption.20}\protected@file@percent }
\newlabel{fig1:110x}{{2.8}{39}{Empirical convergence of nested simulation procedures for different risk measures on Portfolio 1 with $d=20$}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Sensitivity to level for VaR and CVaR}{40}{subsection.2.5.5}\protected@file@percent }
\newlabel{sec1:sensitivity-level}{{2.5.5}{40}{Sensitivity to level for VaR and CVaR}{subsection.2.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Empirical convergence of regression-based procedures for different levels of VaR and CVaR for Up and Out Barrier Call Options}}{40}{figure.caption.21}\protected@file@percent }
\newlabel{fig1:sens_level}{{2.9}{40}{Empirical convergence of regression-based procedures for different levels of VaR and CVaR for Up and Out Barrier Call Options}{figure.caption.21}{}}
\citation{giles2019multilevel}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.6}Sensitivity to the Asset Model}{41}{subsection.2.5.6}\protected@file@percent }
\newlabel{sec1:sensitivity-assetModel}{{2.5.6}{41}{Sensitivity to the Asset Model}{subsection.2.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Empirical convergence of regression-based nested simulation procedures for different asset models}}{41}{figure.caption.22}\protected@file@percent }
\newlabel{fig1:sens_model}{{2.10}{41}{Empirical convergence of regression-based nested simulation procedures for different asset models}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.7}Empirical Convergence of Multi-level Monte Carlo}{41}{subsection.2.5.7}\protected@file@percent }
\newlabel{sec1:empirical-mlmc}{{2.5.7}{41}{Empirical Convergence of Multi-level Monte Carlo}{subsection.2.5.7}{}}
\citation{stothers2010complexity}
\citation{strassen1969gaussian}
\citation{coppersmith1987matrix}
\citation{bentley1975multidimensional}
\citation{kim2008ratio}
\citation{scholkopf2002learning}
\citation{shahriari2015taking}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces MSEs of the multi-level Monte Carlo procedure for different levels}}{42}{table.caption.23}\protected@file@percent }
\newlabel{tab1:mlmc-mse}{{2.4}{42}{MSEs of the multi-level Monte Carlo procedure for different levels}{table.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Computational Complexity}{42}{section.2.6}\protected@file@percent }
\newlabel{sec1:computational-complexity}{{2.6}{42}{Computational Complexity}{section.2.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.5}{\ignorespaces Additional computational costs of nested simulation procedures aside from simulation}}{43}{table.caption.24}\protected@file@percent }
\newlabel{tab1:complexity}{{2.5}{43}{Additional computational costs of nested simulation procedures aside from simulation}{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Total computational cost for different procedures with $d=10$}}{44}{figure.caption.25}\protected@file@percent }
\newlabel{fig1:tcc}{{2.11}{44}{Total computational cost for different procedures with $d=10$}{figure.caption.25}{}}
\citation{zhang2021bootstrap}
\citation{nystrom1930praktische}
\citation{scikit-learn}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Computational cost for implementing nested simulation procedures with $d=10$, excluding simulation time}}{45}{figure.caption.26}\protected@file@percent }
\newlabel{fig1:c_model}{{2.12}{45}{Computational cost for implementing nested simulation procedures with $d=10$, excluding simulation time}{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Conclusion}{46}{section.2.7}\protected@file@percent }
\newlabel{sec1:conclusion}{{2.7}{46}{Conclusion}{section.2.7}{}}
\citation{hastie2009elements,lecun2015deep}
\citation{silver2016mastering}
\citation{chatgpt}
\citation{mcculloch1943logical}
\citation{rosenblatt1958perceptron}
\citation{rumelhart1985learning}
\citation{williams1989learning,sutskever2014sequence}
\citation{hochreiter1997long,chung2014empirical}
\citation{poole2014analyzing}
\citation{neelakantan2015adding}
\citation{luo2016understanding}
\citation{srivastava2014dropout}
\citation{szegedy2013intriguing}
\citation{goodfellow2014explaining}
\citation{carlini2017towards}
\citation{jiang2020beyond}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Cutting Through the Noise: Using Deep Neural Network Metamodels for High Dimensional Nested Simulation}{48}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch2}{{3}{48}{Cutting Through the Noise: Using Deep Neural Network Metamodels for High Dimensional Nested Simulation}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{48}{section.3.1}\protected@file@percent }
\citation{fonseca2003simulation}
\citation{lieu2022adaptive}
\citation{salle2014efficient}
\citation{liu2010stochastic}
\citation{gan2015valuation}
\citation{broadie2015risk}
\citation{hong2017kernel}
\citation{zhang2022sample}
\citation{rockafellar2002conditional}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Problem Formulation}{51}{section.3.2}\protected@file@percent }
\newlabel{sec2:problem-formulation}{{3.2}{51}{Problem Formulation}{section.3.2}{}}
\citation{eiopa2014underlying}
\citation{osfi2017life}
\citation{geneva2013variable}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Tail Risk Measures: VaR and CVaR}{52}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Simulation Model for Variable Annuity Payouts}{52}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:VApayout}{{3.2.2}{52}{Simulation Model for Variable Annuity Payouts}{subsection.3.2.2}{}}
\citation{hardy2003investment}
\citation{dang2021efficient}
\citation{cathcart2015calculating}
\citation{glasserman2004monte}
\newlabel{eq2:delta}{{3.1}{54}{Simulation Model for Variable Annuity Payouts}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Dynamic Hedging for Variable Annuities}{55}{subsection.3.2.3}\protected@file@percent }
\newlabel{subsec:dynamicHedge}{{3.2.3}{55}{Dynamic Hedging for Variable Annuities}{subsection.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Illustration of multi-period nested simulation that estimates the P\&L for one outer scenario.}}{55}{figure.caption.27}\protected@file@percent }
\newlabel{fig2:illustration}{{3.1}{55}{Illustration of multi-period nested simulation that estimates the P\&L for one outer scenario}{figure.caption.27}{}}
\newlabel{eq2:hedgingerror}{{3.2}{56}{Dynamic Hedging for Variable Annuities}{equation.3.2.2}{}}
\newlabel{eq2:lossrv}{{3.3}{56}{Dynamic Hedging for Variable Annuities}{equation.3.2.3}{}}
\citation{dang2020efficient}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Standard Nested Simulation Procedure for Estimating CVaR for GMWB Hedging Losses}}{57}{algorithm.1}\protected@file@percent }
\newlabel{alg2:standardProcedure}{{1}{57}{Standard Nested Simulation Procedure for Estimating CVaR for GMWB Hedging Losses}{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Two-Stage Nested Simulation with Metamodels}{57}{section.3.3}\protected@file@percent }
\newlabel{sec2:metamodel2Stage}{{3.3}{57}{Two-Stage Nested Simulation with Metamodels}{section.3.3}{}}
\citation{dang2020efficient}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Two-Stage Metamodeling Nested Simulation Procedure for Estimating CVaR}}{58}{algorithm.2}\protected@file@percent }
\newlabel{alg2:twoStageProcedure}{{2}{58}{Two-Stage Metamodeling Nested Simulation Procedure for Estimating CVaR}{algorithm.2}{}}
\citation{dang2020efficient}
\citation{dang2020efficient}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Single-Stage Nested Simulation with Neural Network Metamodels}{60}{section.3.4}\protected@file@percent }
\newlabel{sec2:metamodel1Stage}{{3.4}{60}{Single-Stage Nested Simulation with Neural Network Metamodels}{section.3.4}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Single-Stage Metamodeling Nested Simulation Procedure for Estimating CVaR}}{60}{algorithm.3}\protected@file@percent }
\newlabel{alg2:oneStageProcedure}{{3}{60}{Single-Stage Metamodeling Nested Simulation Procedure for Estimating CVaR}{algorithm.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Numerical Results}{60}{section.3.5}\protected@file@percent }
\newlabel{sec2:numerical}{{3.5}{60}{Numerical Results}{section.3.5}{}}
\citation{kingma2014adam}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Architectures and MSEs of metamodels for GMWB inner simulation model.}}{62}{table.caption.28}\protected@file@percent }
\newlabel{tab:gmwb_arch}{{3.1}{62}{Architectures and MSEs of metamodels for GMWB inner simulation model}{table.caption.28}{}}
\newlabel{subfig2:badRNN}{{3.2b}{64}{A bad RNN metamodel}{figure.caption.29}{}}
\newlabel{sub@subfig2:badRNN}{{b}{64}{A bad RNN metamodel}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces QQ-plots between true labels (x-axis) and predicted losses (y-axis) for the RNN metamodel.}}{64}{figure.caption.29}\protected@file@percent }
\newlabel{fig2:QQ_RNN}{{3.2}{64}{QQ-plots between true labels (x-axis) and predicted losses (y-axis) for the RNN metamodel}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces QQ-plots between true losses (x-axis) and predicted losses (y-axis) for regression metamodels.}}{64}{figure.caption.30}\protected@file@percent }
\newlabel{fig2:QQ_REG}{{3.3}{64}{QQ-plots between true losses (x-axis) and predicted losses (y-axis) for regression metamodels}{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces QQ-plots between true losses (x-axis) and predicted losses (y-axis) for neural network metamodels.}}{65}{figure.caption.31}\protected@file@percent }
\newlabel{fig2:QQ_NN}{{3.4}{65}{QQ-plots between true losses (x-axis) and predicted losses (y-axis) for neural network metamodels}{figure.caption.31}{}}
\citation{dang2020efficient}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Two-Stage Procedure}{66}{subsection.3.5.1}\protected@file@percent }
\newlabel{subsec:twoStageProcedure}{{3.5.1}{66}{Two-Stage Procedure}{subsection.3.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Percentage of correctly identified true tail scenarios by different metamodels.}}{66}{figure.caption.32}\protected@file@percent }
\newlabel{fig2:tailMatches}{{3.5}{66}{Percentage of correctly identified true tail scenarios by different metamodels}{figure.caption.32}{}}
\newlabel{subfig2:AllSafetyMargin}{{3.6a}{67}{Safety margin 0\% - 15\%}{figure.caption.33}{}}
\newlabel{sub@subfig2:AllSafetyMargin}{{a}{67}{Safety margin 0\% - 15\%}{figure.caption.33}{}}
\newlabel{subfig2:ZoomedSafetyMargin}{{3.6b}{67}{Safety margin 7.5\% - 15\%}{figure.caption.33}{}}
\newlabel{sub@subfig2:ZoomedSafetyMargin}{{b}{67}{Safety margin 7.5\% - 15\%}{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Average 95\%-CVaR estimates by different procedures. Right figure is a zoomed-in version of left figure.}}{67}{figure.caption.33}\protected@file@percent }
\newlabel{fig2:CVaR95}{{3.6}{67}{Average 95\%-CVaR estimates by different procedures. Right figure is a zoomed-in version of left figure}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Noise Tolerance of Deep Neural Network Metamodels}{68}{subsection.3.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces MSEs of LSTM metamodels.}}{69}{table.caption.34}\protected@file@percent }
\newlabel{tab:lstm_arch}{{3.2}{69}{MSEs of LSTM metamodels}{table.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces QQ-plots between true losses (x-axis) and predicted losses (y-axis) for two LSTM metamodels.}}{70}{figure.caption.35}\protected@file@percent }
\newlabel{fig2:QQ_All}{{3.7}{70}{QQ-plots between true losses (x-axis) and predicted losses (y-axis) for two LSTM metamodels}{figure.caption.35}{}}
\citation{broadie2015risk}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces MSE between regular LSTM predicted losses and true losses.}}{71}{table.caption.36}\protected@file@percent }
\newlabel{tab:lstm_sens}{{3.3}{71}{MSE between regular LSTM predicted losses and true losses}{table.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces MSE between high-capacity LSTM predicted losses and true losses.}}{72}{table.caption.37}\protected@file@percent }
\newlabel{tab:hicaplstm_sens}{{3.4}{72}{MSE between high-capacity LSTM predicted losses and true losses}{table.caption.37}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Spearman (and Pearson) correlation coefficients between regular LSTM predicted losses and true losses.}}{72}{table.caption.38}\protected@file@percent }
\newlabel{tab:lstm_corr}{{3.5}{72}{Spearman (and Pearson) correlation coefficients between regular LSTM predicted losses and true losses}{table.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Single-Stage Procedure}{73}{subsection.3.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces CVaR estimates of the single-stage procedure with metamodels.}}{74}{figure.caption.39}\protected@file@percent }
\newlabel{fig2:CVaRsingleStage}{{3.8}{74}{CVaR estimates of the single-stage procedure with metamodels}{figure.caption.39}{}}
\newlabel{subfig2:convLoCap}{{3.9a}{75}{regular LSTM}{figure.caption.40}{}}
\newlabel{sub@subfig2:convLoCap}{{a}{75}{regular LSTM}{figure.caption.40}{}}
\newlabel{subfig2:convHiCap}{{3.9b}{75}{high-capacity LSTM}{figure.caption.40}{}}
\newlabel{sub@subfig2:convHiCap}{{b}{75}{high-capacity LSTM}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Empirical convergence of CVaR for the single-stage procedure with LSTM metamodels.}}{75}{figure.caption.40}\protected@file@percent }
\newlabel{fig2:gammaConvergence}{{3.9}{75}{Empirical convergence of CVaR for the single-stage procedure with LSTM metamodels}{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Empirical convergence of the single-stage procedure with a LSTM metamodel.}}{76}{figure.caption.41}\protected@file@percent }
\newlabel{fig2:mnConvergence}{{3.10}{76}{Empirical convergence of the single-stage procedure with a LSTM metamodel}{figure.caption.41}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion}{76}{section.3.6}\protected@file@percent }
\newlabel{sec2:conclusion}{{3.6}{76}{Conclusion}{section.3.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Efficient Transfer of Knowledge for Deep Hedging of Variable Annuities}{79}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{79}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Dynamic Hedging of Variable Annuities}{80}{section.4.2}\protected@file@percent }
\newlabel{sec3:vaHedging}{{4.2}{80}{Dynamic Hedging of Variable Annuities}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Markov Decision Process (MDP) for Hedging VAs}{80}{subsection.4.2.1}\protected@file@percent }
\newlabel{eq3:V_pi}{{4.1}{81}{Markov Decision Process (MDP) for Hedging VAs}{equation.4.2.1}{}}
\citation{buehler2019deep}
\citation{imaki2021no}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Deep Hedging Approaches}{82}{subsection.4.2.2}\protected@file@percent }
\citation{glasserman2004monte}
\citation{buehler2019deep}
\citation{mnih2015human}
\citation{lin1992self}
\citation{kolm2019dynamic}
\citation{lillicrap2015continuous}
\citation{xu2022delta}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Value-based and Policy-based Deep Reinforcement Learning}{84}{subsection.4.2.3}\protected@file@percent }
\citation{schulman2017proximal}
\citation{schulman2015trust}
\citation{chong2023pseudo}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Transfer Learning for Risk Management of Variable Annuities}{85}{section.4.3}\protected@file@percent }
\newlabel{sec3:tlHedging}{{4.3}{85}{Transfer Learning for Risk Management of Variable Annuities}{section.4.3}{}}
\citation{xiao2021optimal}
\citation{ng1999policy}
\citation{wiewiora2003principled}
\citation{harutyunyan2015expressing}
\citation{teh2017distral}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Reward Shaping}{87}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Policy Transfer}{87}{subsection.4.3.2}\protected@file@percent }
\citation{andreas2017modular}
\citation{zhang2018decoupling}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Representation Transfer}{88}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Evaluation Metrics}{88}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Plans for Ongoing Numerical Experiments}{89}{section.4.4}\protected@file@percent }
\newlabel{sec3:numerical}{{4.4}{89}{Plans for Ongoing Numerical Experiments}{section.4.4}{}}
\bibstyle{apalike}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Initial Numerical Experiments}{90}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Initial numerical experiments for GMMB}}{91}{figure.caption.42}\protected@file@percent }
\newlabel{fig3:GMMB}{{4.1}{91}{Initial numerical experiments for GMMB}{figure.caption.42}{}}
\bibdata{refP1,refP2,refP3}
\bibcite{andreas2017modular}{{1}{2017}{{Andreas et~al.}}{{}}}
\bibcite{artzner1999coherent}{{2}{1999}{{Artzner et~al.}}{{}}}
\bibcite{barton1998simulation}{{3}{1998}{{Barton}}{{}}}
\bibcite{bauer2008universal}{{4}{2008}{{Bauer et~al.}}{{}}}
\bibcite{bauer2012calculation}{{5}{2012}{{Bauer et~al.}}{{}}}
\bibcite{bentley1975multidimensional}{{6}{1975}{{Bentley}}{{}}}
\bibcite{boyle2003guaranteed}{{7}{2003}{{Boyle and Hardy}}{{}}}
\bibcite{boyle1997reserving}{{8}{1997}{{Boyle and Hardy}}{{}}}
\bibcite{boyle1977equilibrium}{{9}{1977}{{Boyle and Schwartz}}{{}}}
\bibcite{broadie2015risk}{{10}{2015}{{Broadie et~al.}}{{}}}
\bibcite{buehler2019deep}{{11}{2019}{{Buehler et~al.}}{{}}}
\@writefile{toc}{\contentsline {chapter}{\textbf  {References}}{92}{section*.43}\protected@file@percent }
\bibcite{carlini2017towards}{{12}{2017}{{Carlini and Wagner}}{{}}}
\bibcite{caruana2000overfitting}{{13}{2000}{{Caruana et~al.}}{{}}}
\bibcite{cathcart2015calculating}{{14}{2015}{{Cathcart et~al.}}{{}}}
\bibcite{chong2023pseudo}{{15}{2023}{{Chong et~al.}}{{}}}
\bibcite{chung2014empirical}{{16}{2014}{{Chung et~al.}}{{}}}
\bibcite{coppersmith1987matrix}{{17}{1987}{{Coppersmith and Winograd}}{{}}}
\bibcite{dang2021efficient}{{18}{2021}{{Dang}}{{}}}
\bibcite{dang2020efficient}{{19}{2020}{{Dang et~al.}}{{}}}
\bibcite{dang2022dynamic}{{20}{2022}{{Dang et~al.}}{{}}}
\bibcite{dang2023two}{{21}{2023}{{Dang et~al.}}{{}}}
\bibcite{eiopa2014underlying}{{22}{2014}{{EIOPA}}{{}}}
\bibcite{feng2020optimal}{{23}{2020}{{Feng and Song}}{{}}}
\bibcite{feng2016nested}{{24}{2016}{{Feng et~al.}}{{}}}
\bibcite{feng2022variable}{{25}{2022}{{Feng et~al.}}{{}}}
\bibcite{feng2017analytical}{{26}{2017}{{Feng and Jing}}{{}}}
\bibcite{fonseca2003simulation}{{27}{2003}{{Fonseca et~al.}}{{}}}
\bibcite{frazier2018bayesian}{{28}{2018}{{Frazier}}{{}}}
\bibcite{gan2013application}{{29}{2013}{{Gan}}{{}}}
\bibcite{gan2015valuation}{{30}{2015}{{Gan and Lin}}{{}}}
\bibcite{giles2015multilevel}{{31}{2015}{{Giles}}{{}}}
\bibcite{giles2019multilevel}{{32}{2019}{{Giles and Haji-Ali}}{{}}}
\bibcite{giurca2021delta}{{33}{2021}{{Giurca and Borovkova}}{{}}}
\bibcite{glasserman2004monte}{{34}{2004}{{Glasserman}}{{}}}
\bibcite{goodfellow2014explaining}{{35}{2014}{{Goodfellow et~al.}}{{}}}
\bibcite{gordy2010nested}{{36}{2010}{{Gordy and Juneja}}{{}}}
\bibcite{bauer2015least}{{37}{2015}{{Ha and Bauer}}{{}}}
\bibcite{hardle1990applied}{{38}{1990}{{H{\"a}rdle}}{{}}}
\bibcite{hardy2001regime}{{39}{2001}{{Hardy}}{{}}}
\bibcite{hardy2003investment}{{40}{2003}{{Hardy}}{{}}}
\bibcite{hardy2006introduction}{{41}{2006}{{Hardy}}{{}}}
\bibcite{harutyunyan2015expressing}{{42}{2015}{{Harutyunyan et~al.}}{{}}}
\bibcite{hastie2009elements}{{43}{2009}{{Hastie et~al.}}{{}}}
\bibcite{hochreiter1997long}{{44}{1997}{{Hochreiter and Schmidhuber}}{{}}}
\bibcite{hong2014monte}{{45}{2014}{{Hong et~al.}}{{}}}
\bibcite{hong2017kernel}{{46}{2017}{{Hong et~al.}}{{}}}
\bibcite{imaki2021no}{{47}{2021}{{Imaki et~al.}}{{}}}
\bibcite{jabbar2015methods}{{48}{2015}{{Jabbar and Khan}}{{}}}
\bibcite{jennen1988unifying}{{49}{1988}{{Jennen-Steinmetz and Gasser}}{{}}}
\bibcite{jiang2020beyond}{{50}{2020}{{Jiang et~al.}}{{}}}
\bibcite{kim2008ratio}{{51}{2008}{{Kim and Kutzner}}{{}}}
\bibcite{kingma2014adam}{{52}{2014}{{Kingma and Ba}}{{}}}
\bibcite{kolm2019dynamic}{{53}{2019}{{Kolm and Ritter}}{{}}}
\bibcite{krizhevsky2017imagenet}{{54}{2017}{{Krizhevsky et~al.}}{{}}}
\bibcite{lecun2015deep}{{55}{2015}{{LeCun et~al.}}{{}}}
\bibcite{lecun1998gradient}{{56}{1998}{{LeCun et~al.}}{{}}}
\bibcite{lieu2022adaptive}{{57}{2022}{{Lieu et~al.}}{{}}}
\bibcite{lillicrap2015continuous}{{58}{2015}{{Lillicrap et~al.}}{{}}}
\bibcite{lin1992self}{{59}{1992}{{Lin}}{{}}}
\bibcite{lin2020efficient}{{60}{2020a}{{Lin and Yang}}{{}}}
\bibcite{lin2020fast}{{61}{2020b}{{Lin and Yang}}{{}}}
\bibcite{liu2010stochastic}{{62}{2010}{{Liu and Staum}}{{}}}
\bibcite{longstaff2001valuing}{{63}{2001}{{Longstaff and Schwartz}}{{}}}
\bibcite{luo2016understanding}{{64}{2016}{{Luo et~al.}}{{}}}
\bibcite{mack1981local}{{65}{1981}{{Mack}}{{}}}
\bibcite{marshall2010valuation}{{66}{2010}{{Marshall et~al.}}{{}}}
\bibcite{marukame2016error}{{67}{2016}{{Marukame et~al.}}{{}}}
\bibcite{mcculloch1943logical}{{68}{1943}{{McCulloch and Pitts}}{{}}}
\bibcite{mnih2015human}{{69}{2015}{{Mnih et~al.}}{{}}}
\bibcite{naic2021}{{70}{2021}{{NAIC}}{{}}}
\bibcite{neelakantan2015adding}{{71}{2015}{{Neelakantan et~al.}}{{}}}
\bibcite{ng1999policy}{{72}{1999}{{Ng et~al.}}{{}}}
\bibcite{nystrom1930praktische}{{73}{1930}{{Nystr{\"o}m}}{{}}}
\bibcite{chatgpt}{{74}{2023}{{OpenAI}}{{}}}
\bibcite{osfi2017life}{{75}{2017}{{OSFI}}{{}}}
\bibcite{scikit-learn}{{76}{2011}{{Pedregosa et~al.}}{{}}}
\bibcite{peng2020empirical}{{77}{2020}{{Peng and Nagata}}{{}}}
\bibcite{piscopo2011valuation}{{78}{2011}{{Piscopo and Haberman}}{{}}}
\bibcite{poole2014analyzing}{{79}{2014}{{Poole et~al.}}{{}}}
\bibcite{stable-baselines3}{{80}{2021}{{Raffin et~al.}}{{}}}
\bibcite{rockafellar2002conditional}{{81}{2002}{{Rockafellar and Uryasev}}{{}}}
\bibcite{rosenblatt1958perceptron}{{82}{1958}{{Rosenblatt}}{{}}}
\bibcite{ruf2022hedging}{{83}{2022}{{Ruf and Wang}}{{}}}
\bibcite{rumelhart1985learning}{{84}{1985}{{Rumelhart et~al.}}{{}}}
\bibcite{salle2014efficient}{{85}{2014}{{Salle and Y{\i }ld{\i }zo{\u {g}}lu}}{{}}}
\bibcite{scholkopf2002learning}{{86}{2002}{{Sch{\"o}lkopf and Smola}}{{}}}
\bibcite{schulman2015trust}{{87}{2015}{{Schulman et~al.}}{{}}}
\bibcite{schulman2017proximal}{{88}{2017}{{Schulman et~al.}}{{}}}
\bibcite{shahriari2015taking}{{89}{2015}{{Shahriari et~al.}}{{}}}
\bibcite{silver2016mastering}{{90}{2016}{{Silver et~al.}}{{}}}
\bibcite{srivastava2014dropout}{{91}{2014}{{Srivastava et~al.}}{{}}}
\bibcite{stothers2010complexity}{{92}{2010}{{Stothers}}{{}}}
\bibcite{strassen1969gaussian}{{93}{1969}{{Strassen}}{{}}}
\bibcite{sutskever2014sequence}{{94}{2014}{{Sutskever et~al.}}{{}}}
\bibcite{szegedy2013intriguing}{{95}{2013}{{Szegedy et~al.}}{{}}}
\bibcite{teh2017distral}{{96}{2017}{{Teh et~al.}}{{}}}
\bibcite{geneva2013variable}{{97}{2013}{{The Geneva Association}}{{}}}
\bibcite{torres2017fault}{{98}{2017}{{Torres-Huitzil and Girau}}{{}}}
\bibcite{wang2022smooth}{{99}{2022}{{Wang et~al.}}{{}}}
\bibcite{wiewiora2003principled}{{100}{2003}{{Wiewiora et~al.}}{{}}}
\bibcite{williams1989learning}{{101}{1989}{{Williams and Zipser}}{{}}}
\bibcite{wirch1999synthesis}{{102}{1999}{{Wirch and Hardy}}{{}}}
\bibcite{xiao2021optimal}{{103}{2021}{{Xiao et~al.}}{{}}}
\bibcite{xu2022delta}{{104}{2022}{{Xu and Dai}}{{}}}
\bibcite{yang2018bit}{{105}{2018}{{Yang et~al.}}{{}}}
\bibcite{zhang2018decoupling}{{106}{2018}{{Zhang et~al.}}{{}}}
\bibcite{zhang2022sample}{{107}{2022}{{Zhang et~al.}}{{}}}
\bibcite{zhang2021bootstrap}{{108}{2021}{{Zhang et~al.}}{{}}}
\citation{*}
\gdef \@abspage@last{113}
